{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = torch.nn.Sequential( # use max pooling\n",
    "            torch.nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  # 128 -> 64\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), # 64 -> 32\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # 32 -> 16\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # 16 -> 8\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1), # 8 -> 4\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear((128+4)*4*4, 128*4*4)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1), # 4 -> 8\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # 8 -> 16\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1), # 16 -> 32\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1), # 32 -> 64\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1), # 64 -> 128\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, image, action):\n",
    "        x = self.encoder(image)\n",
    "        \n",
    "        action = torch.nn.functional.one_hot(action.to(torch.int64), num_classes=4).reshape(-1, 4, 1, 1).float()\n",
    "        action = action.repeat(1, 1, x.shape[2], x.shape[3])\n",
    "        x = torch.cat((x, action), 1)\n",
    "        x = x.view(-1, (128+4)*x.shape[2]*x.shape[3])\n",
    "        \n",
    "        x = self.layer(x)\n",
    "        x = x.view(-1, 128, 4, 4)\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(\"data/images.npy\")\n",
    "actions = np.load(\"data/actions.npy\")\n",
    "positions_after = np.load(\"data/positions_after.npy\")\n",
    "images_after = np.load(\"data/images_after.npy\")\n",
    "\n",
    "images = images / 255.0 # normalize images\n",
    "images_after = images_after / 255.0 # normalize images\n",
    "\n",
    "# prepare data\n",
    "dataset = torch.utils.data.TensorDataset(torch.tensor(images, dtype=torch.float32), torch.tensor(actions, dtype=torch.float32), torch.tensor(positions_after, dtype=torch.float32), torch.tensor(images_after, dtype=torch.float32))\n",
    "train_size = int(0.8*len(images))\n",
    "valid_size = int(0.1*len(images))\n",
    "test_size = len(images) - train_size - valid_size\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_images, valid_actions, valid_positions_after, valid_images_after = valid_dataset[:]\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train():\n",
    "    reconstruction_model = Autoencoder().to(device)\n",
    "    optimizer = torch.optim.Adam(reconstruction_model.parameters(), lr=0.0025)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    num_epochs = 2000\n",
    "\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # training\n",
    "        running_loss = 0.0\n",
    "        for i, (images, actions, positions_after, images_after) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            actions = actions.to(device)\n",
    "            positions_after = positions_after.to(device)\n",
    "            images_after = images_after.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = reconstruction_model(images, actions)\n",
    "            loss = criterion(outputs, images_after)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()*images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss/len(train_loader.dataset)\n",
    "        training_losses.append(epoch_loss)\n",
    "        \n",
    "        # validation\n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            outputs = reconstruction_model(valid_images.to(device), valid_actions.to(device))\n",
    "            valid_loss = criterion(outputs, valid_images_after.to(device))\n",
    "            validation_losses.append(valid_loss.item())\n",
    "            print(epoch, epoch_loss)\n",
    "            if validation_losses[-1] == min(validation_losses):\n",
    "                print(\"Saving best model, epoch: \", epoch)\n",
    "                torch.save(reconstruction_model.state_dict(), \"hw1_3.pth\")\n",
    "    return training_losses\n",
    "\n",
    "def test():\n",
    "    reconstruction_model = Autoencoder()\n",
    "    reconstruction_model.load_state_dict(torch.load(\"hw1_3.pth\"))\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    test_losses = []\n",
    "    with torch.no_grad():\n",
    "        for i, (images, actions, positions_after, images_after) in enumerate(test_loader):\n",
    "\n",
    "            outputs = reconstruction_model(images, actions)\n",
    "            loss = criterion(outputs, images_after)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "            # visualize the result\n",
    "            if i == 0:\n",
    "                images = images.cpu().numpy()\n",
    "                outputs = outputs.cpu().numpy()\n",
    "                images_after = images_after.cpu().numpy()\n",
    "                for j in range(5):\n",
    "                    plt.subplot(3, 5, j+1)\n",
    "                    plt.imshow(images[j].transpose(1, 2, 0))\n",
    "                    if j == 0:\n",
    "                        plt.ylabel(\"Input\")\n",
    "                    plt.yticks([])\n",
    "                    plt.xticks([])\n",
    "                    #plt.axis(\"off\")\n",
    "                    plt.subplot(3, 5, j+6)\n",
    "                    plt.imshow(outputs[j].transpose(1, 2, 0))\n",
    "                    if j == 0:\n",
    "                        plt.ylabel(\"Output\")\n",
    "                    plt.yticks([])\n",
    "                    plt.xticks([])\n",
    "                    #plt.axis(\"off\")\n",
    "                    plt.subplot(3, 5, j+11)\n",
    "                    plt.imshow(images_after[j].transpose(1, 2, 0))\n",
    "                    if j == 0:\n",
    "                        plt.ylabel(\"Ground Truth\")\n",
    "                    plt.yticks([])\n",
    "                    plt.xticks([])\n",
    "                    #plt.axis(\"off\")\n",
    "                plt.savefig(\"results/reconstruction_test_results.png\")\n",
    "                plt.close()\n",
    "    return test_losses\n",
    "\n",
    "\n",
    "def plot_loss(training_losses):\n",
    "    plt.figure()\n",
    "    plt.plot(training_losses)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (Log Scale)')\n",
    "    plt.title('Training Loss of Image Reconstruction Model')\n",
    "    plt.savefig('results/reconstruction_training_loss.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = train()\n",
    "plot_loss(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = test()\n",
    "\n",
    "## write to file\n",
    "with open(\"results/reconstruction_test_results.txt\", \"w\") as f:\n",
    "    f.write(\"Reconstruction test loss: \" + str(test_losses) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpe591",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
